{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本笔记本使用大庆数据hdf5文件进行标准化处理过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大庆数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义常量和配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants.py\n",
    "\n",
    "# 列名\n",
    "COLUMNS = ['DEPT', 'RMN-RMG', 'CAL', 'SP', 'GR', 'HAC', 'BHC', 'DEN']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. H5文件模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Description: This HDF5 file contains oil well log data collected from various wells in the North Sea region. The data includes measurements of depth, resistivity, caliper, sound velocity, gamma ray, and density, among others. The measurements were taken using a combination of logging tools and techniques, including electrical resistivity logging (ERL), caliper logging, and gamma ray logging. The data has been processed to ensure consistency and accuracy, including normalization and interpolation where necessary. This file is intended for use in geological and geophysical analyses, particularly in the study of oil and gas reservoirs. For any questions or further information, please contact the data provider at [email protected]\n",
      "Reading BHC...\n",
      "BHC: Unit = us/m, Description = 表面声波时差，没有明确单位，可能是微秒每米 (.us/m)，因为与HAC类似\n",
      "Reading CAL...\n",
      "CAL: Unit = cm, Description = 孔隙径，单位为厘米 (.cm)\n",
      "Reading DEN...\n",
      "DEN: Unit = g/cm3, Description = 密度，单位为克/立方厘米 (.g/cm3)\n",
      "Reading DEPT...\n",
      "DEPT: Unit = m, Description = 深度，单位为米 (.M)\n",
      "Reading GR...\n",
      "GR: Unit = API or unitless, Description = 伽马射线，单位未明确指出，但通常伽马射线的单位是API（美国石油学会单位）或者无单位\n",
      "Reading HAC...\n",
      "HAC: Unit = us/m, Description = 声波时差，单位为微秒每米 (.us/m)\n",
      "Reading RMG...\n",
      "RMG: Unit = ohmm, Description = 电阻率，单位为欧姆米 (.ohmm)\n",
      "Reading RMN...\n",
      "RMN: Unit = ohmm, Description = 电阻率，单位为欧姆米 (.ohmm)\n",
      "Reading RMN-RMG...\n",
      "RMN-RMG: Unit = ohmm, Description = 电阻率差值，没有明确单位，但由于是RMN与RMG的差值，其单位应该也是欧姆米 (.ohmm)\n",
      "Reading SP...\n",
      "SP: Unit = mv, Description = 自发电位，单位为毫伏 (.mv)\n",
      "Reading WellName...\n",
      "WellName: Unit = No unit, Description = No description\n",
      "       BHC     CAL    DEN    DEPT       GR      HAC    RMG    RMN  RMN-RMG  \\\n",
      "0  405.716  23.492  2.269  780.60  102.405  402.244  2.260  2.265    0.005   \n",
      "1  404.701  23.453  2.274  780.65  103.093  397.115  2.241  2.281    0.040   \n",
      "2  403.953  23.403  2.284  780.70  102.995  394.872  2.405  2.474    0.069   \n",
      "3  404.434  23.363  2.274  780.75  102.405  397.009  2.598  2.640    0.042   \n",
      "4  405.021  23.333  2.284  780.80  101.128  404.060  2.533  2.538    0.005   \n",
      "\n",
      "        SP WellName  \n",
      "0  121.845       A1  \n",
      "1  121.845       A1  \n",
      "2  121.656       A1  \n",
      "3  121.325       A1  \n",
      "4  120.994       A1  \n"
     ]
    }
   ],
   "source": [
    "# data_read.py\n",
    "\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_h5(filename):\n",
    "    \"\"\"\n",
    "    从.h5文件中读取数据，并返回一个Pandas DataFrame。\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): 文件名，包括路径和扩展名。\n",
    "\n",
    "    Returns:\n",
    "    - df (DataFrame): 包含从文件中读取的数据的DataFrame。\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as h5f:\n",
    "        # 获取文件的描述信息\n",
    "        file_description = h5f.attrs.get('file_description', 'No description')\n",
    "        print(f\"File Description: {file_description}\")\n",
    "        \n",
    "        # 初始化一个空的DataFrame\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        # 遍历文件中的所有数据集\n",
    "        for key in h5f.keys():\n",
    "            print(f\"Reading {key}...\")\n",
    "            # 读取数据集\n",
    "            dataset = h5f[key]\n",
    "            # 将数据集添加到DataFrame中\n",
    "            df[key] = dataset[:]\n",
    "            # 打印数据集的单位和描述\n",
    "            unit = dataset.attrs.get('unit', 'No unit')\n",
    "            description = dataset.attrs.get('description', 'No description')\n",
    "            print(f\"{key}: Unit = {unit}, Description = {description}\")\n",
    "        \n",
    "        # 在添加数据集到DataFrame之后，将WellName列中的字节字符串转换为字符串\n",
    "        df['WellName'] = df['WellName'].apply(lambda x: x.decode('utf-8'))\n",
    "        return df\n",
    "\n",
    "filename = './well_log_daqing.h5'\n",
    "df = load_data_from_h5(filename)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 数据处理模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据之后，需要进行标准化出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_process.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "# form constants import COLUMNS\n",
    "\n",
    "class DataStandardizer:\n",
    "    \"\"\"\n",
    "    数据标准化类，使用StandardScaler进行标准化。\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.columns = columns\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        拟合标准化器。\n",
    "        \"\"\"\n",
    "        if self.columns is None:\n",
    "            self.columns = df.columns\n",
    "        self.scaler.fit(df[self.columns])\n",
    "        self.fitted = True\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"  \n",
    "        对数据进行标准化。\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler is not fitted yet. Call 'fit' with appropriate data before transforming.\")\n",
    "        # 标准化指定的列\n",
    "        df_standardized = pd.DataFrame(self.scaler.transform(df[self.columns]), columns=self.columns)\n",
    "        # 将标准化后的列替换原始数据框中的对应列\n",
    "        for col in self.columns:\n",
    "            df[col] = df_standardized[col]\n",
    "        return df\n",
    "\n",
    "    def inverse_transform(self, df):\n",
    "        \"\"\" \n",
    "        对标准化后的数据进行反标准化。\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler is not fitted yet. Call 'fit' with appropriate data before inverse transforming.\")\n",
    "        # 反标准化指定的列\n",
    "        df_standardized = pd.DataFrame(self.scaler.inverse_transform(df[self.columns]), columns=self.columns)\n",
    "        # 将反标准化后的列替换原始数据框中的对应列\n",
    "        for col in self.columns:\n",
    "            df[col] = df_standardized[col]\n",
    "        return df\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"  \n",
    "        保存标准化器。\n",
    "        \"\"\"\n",
    "        joblib.dump(self.scaler, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\" \n",
    "        加载标准化器。\n",
    "        \"\"\"\n",
    "        self.scaler = joblib.load(filename)\n",
    "        self.fitted = True\n",
    "\n",
    "# 示例使用\n",
    "standardizer = DataStandardizer(columns= COLUMNS) # 指定需要标准化的列\n",
    "standardizer.fit(df) # 使用df数据进行标准化\n",
    "df_standardized = standardizer.transform(df) # 标准化df数据\n",
    "\n",
    "# 保存标准化器\n",
    "standardizer.save('scaler.joblib')\n",
    "\n",
    "# # 加载标准化器\n",
    "# standardizer.load('scaler.joblib')\n",
    "\n",
    "# # 反标准化\n",
    "# df_original = standardizer.inverse_transform(df_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BHC</th>\n",
       "      <th>CAL</th>\n",
       "      <th>DEN</th>\n",
       "      <th>DEPT</th>\n",
       "      <th>GR</th>\n",
       "      <th>HAC</th>\n",
       "      <th>RMG</th>\n",
       "      <th>RMN</th>\n",
       "      <th>RMN-RMG</th>\n",
       "      <th>SP</th>\n",
       "      <th>WellName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.354331</td>\n",
       "      <td>1.382265</td>\n",
       "      <td>0.021540</td>\n",
       "      <td>-1.575040</td>\n",
       "      <td>-0.076729</td>\n",
       "      <td>1.203110</td>\n",
       "      <td>2.260</td>\n",
       "      <td>2.265</td>\n",
       "      <td>-0.687548</td>\n",
       "      <td>1.389699</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.331241</td>\n",
       "      <td>1.345440</td>\n",
       "      <td>0.073887</td>\n",
       "      <td>-1.574611</td>\n",
       "      <td>-0.067284</td>\n",
       "      <td>1.092743</td>\n",
       "      <td>2.241</td>\n",
       "      <td>2.281</td>\n",
       "      <td>-0.658715</td>\n",
       "      <td>1.389699</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.314226</td>\n",
       "      <td>1.298230</td>\n",
       "      <td>0.178583</td>\n",
       "      <td>-1.574182</td>\n",
       "      <td>-0.068630</td>\n",
       "      <td>1.044477</td>\n",
       "      <td>2.405</td>\n",
       "      <td>2.474</td>\n",
       "      <td>-0.634824</td>\n",
       "      <td>1.378332</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.325168</td>\n",
       "      <td>1.260461</td>\n",
       "      <td>0.073887</td>\n",
       "      <td>-1.573753</td>\n",
       "      <td>-0.076729</td>\n",
       "      <td>1.090462</td>\n",
       "      <td>2.598</td>\n",
       "      <td>2.640</td>\n",
       "      <td>-0.657067</td>\n",
       "      <td>1.358426</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.338521</td>\n",
       "      <td>1.232135</td>\n",
       "      <td>0.178583</td>\n",
       "      <td>-1.573324</td>\n",
       "      <td>-0.094258</td>\n",
       "      <td>1.242187</td>\n",
       "      <td>2.533</td>\n",
       "      <td>2.538</td>\n",
       "      <td>-0.687548</td>\n",
       "      <td>1.338520</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38729</th>\n",
       "      <td>-0.231540</td>\n",
       "      <td>-0.852690</td>\n",
       "      <td>-1.580308</td>\n",
       "      <td>0.359415</td>\n",
       "      <td>-0.367605</td>\n",
       "      <td>-0.233752</td>\n",
       "      <td>6.191</td>\n",
       "      <td>8.237</td>\n",
       "      <td>0.993849</td>\n",
       "      <td>-1.949959</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38730</th>\n",
       "      <td>-0.282565</td>\n",
       "      <td>-0.881016</td>\n",
       "      <td>-1.287160</td>\n",
       "      <td>0.359844</td>\n",
       "      <td>-0.346479</td>\n",
       "      <td>-0.233752</td>\n",
       "      <td>5.867</td>\n",
       "      <td>8.042</td>\n",
       "      <td>1.100121</td>\n",
       "      <td>-1.953868</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38731</th>\n",
       "      <td>-0.332362</td>\n",
       "      <td>-0.895179</td>\n",
       "      <td>-1.077768</td>\n",
       "      <td>0.360273</td>\n",
       "      <td>-0.320068</td>\n",
       "      <td>-0.240638</td>\n",
       "      <td>6.723</td>\n",
       "      <td>9.164</td>\n",
       "      <td>1.319255</td>\n",
       "      <td>-1.959762</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38732</th>\n",
       "      <td>-0.373673</td>\n",
       "      <td>-0.859299</td>\n",
       "      <td>-0.931194</td>\n",
       "      <td>0.360702</td>\n",
       "      <td>-0.279134</td>\n",
       "      <td>-0.240638</td>\n",
       "      <td>7.263</td>\n",
       "      <td>9.530</td>\n",
       "      <td>1.175912</td>\n",
       "      <td>-1.953868</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38733</th>\n",
       "      <td>-0.496356</td>\n",
       "      <td>-0.798870</td>\n",
       "      <td>-0.920724</td>\n",
       "      <td>0.361131</td>\n",
       "      <td>-0.248756</td>\n",
       "      <td>-0.587599</td>\n",
       "      <td>6.874</td>\n",
       "      <td>8.828</td>\n",
       "      <td>0.918059</td>\n",
       "      <td>-1.949959</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38734 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BHC       CAL       DEN      DEPT        GR       HAC    RMG  \\\n",
       "0      1.354331  1.382265  0.021540 -1.575040 -0.076729  1.203110  2.260   \n",
       "1      1.331241  1.345440  0.073887 -1.574611 -0.067284  1.092743  2.241   \n",
       "2      1.314226  1.298230  0.178583 -1.574182 -0.068630  1.044477  2.405   \n",
       "3      1.325168  1.260461  0.073887 -1.573753 -0.076729  1.090462  2.598   \n",
       "4      1.338521  1.232135  0.178583 -1.573324 -0.094258  1.242187  2.533   \n",
       "...         ...       ...       ...       ...       ...       ...    ...   \n",
       "38729 -0.231540 -0.852690 -1.580308  0.359415 -0.367605 -0.233752  6.191   \n",
       "38730 -0.282565 -0.881016 -1.287160  0.359844 -0.346479 -0.233752  5.867   \n",
       "38731 -0.332362 -0.895179 -1.077768  0.360273 -0.320068 -0.240638  6.723   \n",
       "38732 -0.373673 -0.859299 -0.931194  0.360702 -0.279134 -0.240638  7.263   \n",
       "38733 -0.496356 -0.798870 -0.920724  0.361131 -0.248756 -0.587599  6.874   \n",
       "\n",
       "         RMN   RMN-RMG        SP WellName  \n",
       "0      2.265 -0.687548  1.389699       A1  \n",
       "1      2.281 -0.658715  1.389699       A1  \n",
       "2      2.474 -0.634824  1.378332       A1  \n",
       "3      2.640 -0.657067  1.358426       A1  \n",
       "4      2.538 -0.687548  1.338520       A1  \n",
       "...      ...       ...       ...      ...  \n",
       "38729  8.237  0.993849 -1.949959       A6  \n",
       "38730  8.042  1.100121 -1.953868       A6  \n",
       "38731  9.164  1.319255 -1.959762       A6  \n",
       "38732  9.530  1.175912 -1.953868       A6  \n",
       "38733  8.828  0.918059 -1.949959       A6  \n",
       "\n",
       "[38734 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 数据保存模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_save.py\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def save_data_to_h5(data, filename, file_description):\n",
    "    \"\"\"\n",
    "    将数据保存为.h5文件，并添加文件的描述信息作为属性。\n",
    "\n",
    "    Parameters:\n",
    "    - data (DataFrame or ndarray): 要保存的数据。\n",
    "    - filename (str): 文件名，包括路径和扩展名。\n",
    "    - file_description (str): 整个文件的描述信息。\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'w') as h5f:\n",
    "        # 添加整个文件的描述信息作为根组的属性\n",
    "        h5f.attrs['file_description'] = file_description\n",
    "        \n",
    "        # 创建数据集\n",
    "        for key in data.columns:\n",
    "            dataset = h5f.create_dataset(key, data=data[key].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_h5(filename):\n",
    "    \"\"\"\n",
    "    从.h5文件中读取数据和文件描述信息。\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): 文件名，包括路径和扩展名。\n",
    "\n",
    "    Returns:\n",
    "    - data (DataFrame): 从文件中读取的数据。\n",
    "    - file_description (str): 文件的描述信息。\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as h5f:\n",
    "        # 读取文件描述信息\n",
    "        file_description = h5f.attrs.get('file_description', 'No description available')\n",
    "\n",
    "        data = {key: h5f[key][()] for key in h5f.keys()}\n",
    "        # 将数据转换为DataFrame\n",
    "        data_df = pd.DataFrame(data)\n",
    "        \n",
    "        # 在添加数据集到DataFrame之后，将WellName列中的字节字符串转换为字符串\n",
    "        data_df['WellName'] = data_df['WellName'].apply(lambda x: x.decode('utf-8'))\n",
    "\n",
    "        return data_df, file_description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存为well_log_daqing_standardized.h5。还有一个标准化器scaler.joblib。使用的标准化器为StandardScaler。\n"
     ]
    }
   ],
   "source": [
    "file_description = \"将标准化后的数据保存为.h5文件，以便后续使用。标准化器为StandardScaler。\"\n",
    "save_data_to_h5(df_standardized, 'well_log_daqing_standardized.h5', file_description)\n",
    "print(\"数据已保存为well_log_daqing_standardized.h5。还有一个标准化器scaler.joblib。使用的标准化器为StandardScaler。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Description: 将标准化后的数据保存为.h5文件，以便后续使用。标准化器为StandardScaler。\n",
      "Data:             BHC       CAL       DEN      DEPT        GR       HAC    RMG  \\\n",
      "0      1.354331  1.382265  0.021540 -1.575040 -0.076729  1.203110  2.260   \n",
      "1      1.331241  1.345440  0.073887 -1.574611 -0.067284  1.092743  2.241   \n",
      "2      1.314226  1.298230  0.178583 -1.574182 -0.068630  1.044477  2.405   \n",
      "3      1.325168  1.260461  0.073887 -1.573753 -0.076729  1.090462  2.598   \n",
      "4      1.338521  1.232135  0.178583 -1.573324 -0.094258  1.242187  2.533   \n",
      "...         ...       ...       ...       ...       ...       ...    ...   \n",
      "38729 -0.231540 -0.852690 -1.580308  0.359415 -0.367605 -0.233752  6.191   \n",
      "38730 -0.282565 -0.881016 -1.287160  0.359844 -0.346479 -0.233752  5.867   \n",
      "38731 -0.332362 -0.895179 -1.077768  0.360273 -0.320068 -0.240638  6.723   \n",
      "38732 -0.373673 -0.859299 -0.931194  0.360702 -0.279134 -0.240638  7.263   \n",
      "38733 -0.496356 -0.798870 -0.920724  0.361131 -0.248756 -0.587599  6.874   \n",
      "\n",
      "         RMN   RMN-RMG        SP WellName  \n",
      "0      2.265 -0.687548  1.389699       A1  \n",
      "1      2.281 -0.658715  1.389699       A1  \n",
      "2      2.474 -0.634824  1.378332       A1  \n",
      "3      2.640 -0.657067  1.358426       A1  \n",
      "4      2.538 -0.687548  1.338520       A1  \n",
      "...      ...       ...       ...      ...  \n",
      "38729  8.237  0.993849 -1.949959       A6  \n",
      "38730  8.042  1.100121 -1.953868       A6  \n",
      "38731  9.164  1.319255 -1.959762       A6  \n",
      "38732  9.530  1.175912 -1.953868       A6  \n",
      "38733  8.828  0.918059 -1.949959       A6  \n",
      "\n",
      "[38734 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# 示例使用\n",
    "filename = './well_log_daqing_standardized.h5' # 请替换为您的文件名\n",
    "data, description = load_data_from_h5(filename)\n",
    "print(\"File Description:\", description)\n",
    "print(\"Data:\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取标准化数据之后，测试数据的反标准化是否正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BHC</th>\n",
       "      <th>CAL</th>\n",
       "      <th>DEN</th>\n",
       "      <th>DEPT</th>\n",
       "      <th>GR</th>\n",
       "      <th>HAC</th>\n",
       "      <th>RMG</th>\n",
       "      <th>RMN</th>\n",
       "      <th>RMN-RMG</th>\n",
       "      <th>SP</th>\n",
       "      <th>WellName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405.716</td>\n",
       "      <td>23.492</td>\n",
       "      <td>2.269</td>\n",
       "      <td>780.600</td>\n",
       "      <td>102.405</td>\n",
       "      <td>402.244</td>\n",
       "      <td>2.260</td>\n",
       "      <td>2.265</td>\n",
       "      <td>0.005</td>\n",
       "      <td>121.845</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404.701</td>\n",
       "      <td>23.453</td>\n",
       "      <td>2.274</td>\n",
       "      <td>780.650</td>\n",
       "      <td>103.093</td>\n",
       "      <td>397.115</td>\n",
       "      <td>2.241</td>\n",
       "      <td>2.281</td>\n",
       "      <td>0.040</td>\n",
       "      <td>121.845</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>403.953</td>\n",
       "      <td>23.403</td>\n",
       "      <td>2.284</td>\n",
       "      <td>780.700</td>\n",
       "      <td>102.995</td>\n",
       "      <td>394.872</td>\n",
       "      <td>2.405</td>\n",
       "      <td>2.474</td>\n",
       "      <td>0.069</td>\n",
       "      <td>121.656</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>404.434</td>\n",
       "      <td>23.363</td>\n",
       "      <td>2.274</td>\n",
       "      <td>780.750</td>\n",
       "      <td>102.405</td>\n",
       "      <td>397.009</td>\n",
       "      <td>2.598</td>\n",
       "      <td>2.640</td>\n",
       "      <td>0.042</td>\n",
       "      <td>121.325</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>405.021</td>\n",
       "      <td>23.333</td>\n",
       "      <td>2.284</td>\n",
       "      <td>780.800</td>\n",
       "      <td>101.128</td>\n",
       "      <td>404.060</td>\n",
       "      <td>2.533</td>\n",
       "      <td>2.538</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.994</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38729</th>\n",
       "      <td>336.003</td>\n",
       "      <td>21.125</td>\n",
       "      <td>2.116</td>\n",
       "      <td>1006.079</td>\n",
       "      <td>81.215</td>\n",
       "      <td>335.470</td>\n",
       "      <td>6.191</td>\n",
       "      <td>8.237</td>\n",
       "      <td>2.046</td>\n",
       "      <td>66.313</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38730</th>\n",
       "      <td>333.760</td>\n",
       "      <td>21.095</td>\n",
       "      <td>2.144</td>\n",
       "      <td>1006.129</td>\n",
       "      <td>82.754</td>\n",
       "      <td>335.470</td>\n",
       "      <td>5.867</td>\n",
       "      <td>8.042</td>\n",
       "      <td>2.175</td>\n",
       "      <td>66.248</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38731</th>\n",
       "      <td>331.571</td>\n",
       "      <td>21.080</td>\n",
       "      <td>2.164</td>\n",
       "      <td>1006.179</td>\n",
       "      <td>84.678</td>\n",
       "      <td>335.150</td>\n",
       "      <td>6.723</td>\n",
       "      <td>9.164</td>\n",
       "      <td>2.441</td>\n",
       "      <td>66.150</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38732</th>\n",
       "      <td>329.755</td>\n",
       "      <td>21.118</td>\n",
       "      <td>2.178</td>\n",
       "      <td>1006.229</td>\n",
       "      <td>87.660</td>\n",
       "      <td>335.150</td>\n",
       "      <td>7.263</td>\n",
       "      <td>9.530</td>\n",
       "      <td>2.267</td>\n",
       "      <td>66.248</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38733</th>\n",
       "      <td>324.362</td>\n",
       "      <td>21.182</td>\n",
       "      <td>2.179</td>\n",
       "      <td>1006.279</td>\n",
       "      <td>89.873</td>\n",
       "      <td>319.026</td>\n",
       "      <td>6.874</td>\n",
       "      <td>8.828</td>\n",
       "      <td>1.954</td>\n",
       "      <td>66.313</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38734 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           BHC     CAL    DEN      DEPT       GR      HAC    RMG    RMN  \\\n",
       "0      405.716  23.492  2.269   780.600  102.405  402.244  2.260  2.265   \n",
       "1      404.701  23.453  2.274   780.650  103.093  397.115  2.241  2.281   \n",
       "2      403.953  23.403  2.284   780.700  102.995  394.872  2.405  2.474   \n",
       "3      404.434  23.363  2.274   780.750  102.405  397.009  2.598  2.640   \n",
       "4      405.021  23.333  2.284   780.800  101.128  404.060  2.533  2.538   \n",
       "...        ...     ...    ...       ...      ...      ...    ...    ...   \n",
       "38729  336.003  21.125  2.116  1006.079   81.215  335.470  6.191  8.237   \n",
       "38730  333.760  21.095  2.144  1006.129   82.754  335.470  5.867  8.042   \n",
       "38731  331.571  21.080  2.164  1006.179   84.678  335.150  6.723  9.164   \n",
       "38732  329.755  21.118  2.178  1006.229   87.660  335.150  7.263  9.530   \n",
       "38733  324.362  21.182  2.179  1006.279   89.873  319.026  6.874  8.828   \n",
       "\n",
       "       RMN-RMG       SP WellName  \n",
       "0        0.005  121.845       A1  \n",
       "1        0.040  121.845       A1  \n",
       "2        0.069  121.656       A1  \n",
       "3        0.042  121.325       A1  \n",
       "4        0.005  120.994       A1  \n",
       "...        ...      ...      ...  \n",
       "38729    2.046   66.313       A6  \n",
       "38730    2.175   66.248       A6  \n",
       "38731    2.441   66.150       A6  \n",
       "38732    2.267   66.248       A6  \n",
       "38733    1.954   66.313       A6  \n",
       "\n",
       "[38734 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# 加载标准化器\n",
    "\n",
    "standardizer = DataStandardizer(columns= COLUMNS) # 指定需要标准化的列\n",
    "# 加载标准化器\n",
    "standardizer.load('scaler.joblib')\n",
    "\n",
    "df_standardized = data\n",
    "\n",
    "# 反标准化\n",
    "df_original = standardizer.inverse_transform(df_standardized)\n",
    "\n",
    "df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "# from data_read import load_data_from_h5\n",
    "# from data_process import DataStandardizer\n",
    "# from data_save import save_data_to_h5\n",
    "# from constants import COLUMNS\n",
    "\n",
    "def main():\n",
    "    # 加载数据\n",
    "    filename = './well_log_daqing_standardized.h5'\n",
    "    data, description = load_data_from_h5(filename)\n",
    "\n",
    "    # 创建标准化器并拟合\n",
    "    standardizer = DataStandardizer(columns=COLUMNS)\n",
    "    standardizer.fit(data)\n",
    "\n",
    "    # 标准化数据\n",
    "    data_standardized = standardizer.transform(data)\n",
    "\n",
    "    # 保存标准化后的数据\n",
    "    file_description = \"标准化后的数据\"\n",
    "    save_data_to_h5(data_standardized, 'well_log_daqing_standardized.h5', file_description)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader.py\n",
    "\n",
    "class DataLoaderStrategy:\n",
    "    \"\"\"\n",
    "    数据加载策略的基类。\n",
    "    \"\"\"\n",
    "    def load_data(self, filename):\n",
    "        \"\"\"\n",
    "        加载数据的方法。\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement this method.\")\n",
    "    \n",
    "class AdvancedDataLoader(DataLoaderStrategy):\n",
    "    \"\"\"\n",
    "    高级的数据加载策略，使用其他方式加载数据。\n",
    "    \n",
    "    \"\"\"\n",
    "    def load_data(self, filename):\n",
    "        # 实现高级的数据加载逻辑\n",
    "        with h5py.File(filename, 'r') as h5f:\n",
    "            file_description = h5f.attrs.get('file_description', 'No description')\n",
    "            print(f\"File Description: {file_description}\")\n",
    "            data_df = pd.DataFrame()\n",
    "            for key in h5f.keys():\n",
    "                dataset = h5f[key]\n",
    "                data_df[key] = dataset[:]\n",
    "                unit = dataset.attrs.get('unit', 'No unit')\n",
    "                description = dataset.attrs.get('description', 'No description')\n",
    "                print(f\"{key}: Unit = {unit}, Description = {description}\")\n",
    "            data_df['WellName'] = data_df['WellName'].apply(lambda x: x.decode('utf-8'))\n",
    "            return data_df\n",
    "            \n",
    "class DefaultDataLoader(DataLoaderStrategy):\n",
    "    \"\"\"\n",
    "    默认的数据加载策略，使用data_read.py中的load_data_from_h5函数加载数据。\n",
    "    \"\"\"\n",
    "    def load_data(self, filename):\n",
    "        # 实现默认的数据加载逻辑\n",
    "        with h5py.File(filename, 'r') as h5f:\n",
    "            data = {key: h5f[key][()] for key in h5f.keys()}\n",
    "            data_df = pd.DataFrame(data)\n",
    "            data_df['WellName'] = data_df['WellName'].apply(lambda x: x.decode('utf-8'))\n",
    "            return data_df\n",
    "        \n",
    "def load_data_from_h5(filename, strategy=DefaultDataLoader()):\n",
    "    return strategy.load_data(filename)\n",
    "\n",
    "\n",
    "# # 1. 默认数据加载策略\n",
    "# # 导入必要的库\n",
    "# import pandas as pd\n",
    "# import h5py\n",
    "\n",
    "# # 使用默认数据加载策略加载数据\n",
    "# filename = \"./well_log_daqing_standardized.h5\"\n",
    "# data_loader = DefaultDataLoader()\n",
    "# df = load_data_from_h5(filename, strategy=data_loader)\n",
    "\n",
    "# # 打印加载的数据\n",
    "# print(df.head())\n",
    "\n",
    "# # 1. 高级数据加载策略\n",
    "# # 导入必要的库\n",
    "# import pandas as pd\n",
    "# import h5py\n",
    "\n",
    "# # 使用高级数据加载策略加载数据\n",
    "# filename = \"./well_log_daqing.h5\"\n",
    "# data_loader = AdvancedDataLoader()\n",
    "# df = load_data_from_h5(filename, strategy=data_loader)\n",
    "\n",
    "# # 打印加载的数据和文件描述信息\n",
    "# print(df.head())\n",
    "# print(f\"File Description: {file_description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_saver.py\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "# from columns_description import COLUMN_DESCRIPTIONS\n",
    "# columns_description.py\n",
    "# 列描述\n",
    "COLUMN_DESCRIPTIONS = {\n",
    "    'DEPT': {\n",
    "        'unit': 'm',\n",
    "        'description': '深度，单位为米 (.M)'\n",
    "    },\n",
    "    'RMG': {\n",
    "        'unit': 'ohmm',\n",
    "        'description': '电阻率，单位为欧姆米 (.ohmm)'\n",
    "    },\n",
    "    'RMN': {\n",
    "        'unit': 'ohmm',\n",
    "        'description': '电阻率，单位为欧姆米 (.ohmm)'\n",
    "    },\n",
    "    'RMN-RMG': {\n",
    "        'unit': 'ohmm',\n",
    "        'description': '电阻率差值，没有明确单位，但由于是RMN与RMG的差值，其单位应该也是欧姆米 (.ohmm)'\n",
    "    },\n",
    "    'CAL': {\n",
    "        'unit': 'cm',\n",
    "        'description': '孔隙径，单位为厘米 (.cm)'\n",
    "    },\n",
    "    'SP': {\n",
    "        'unit': 'mv',\n",
    "        'description': '自发电位，单位为毫伏 (.mv)'\n",
    "    },\n",
    "    'GR': {\n",
    "        'unit': 'API or unitless',\n",
    "        'description': '伽马射线，单位未明确指出，但通常伽马射线的单位是API（美国石油学会单位）或者无单位'\n",
    "    },\n",
    "    'HAC': {\n",
    "        'unit': 'us/m',\n",
    "        'description': '声波时差，单位为微秒每米 (.us/m)'\n",
    "    },\n",
    "    'BHC': {\n",
    "        'unit': 'us/m',\n",
    "        'description': '表面声波时差，没有明确单位，可能是微秒每米 (.us/m)，因为与HAC类似'\n",
    "    },\n",
    "    'DEN': {\n",
    "        'unit': 'g/cm3',\n",
    "        'description': '密度，单位为克/立方厘米 (.g/cm3)'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "class DataSaveStrategy:\n",
    "    \"\"\"\n",
    "    数据保存策略的基类。\n",
    "    \"\"\"\n",
    "    def save_data(self, data, filename, file_description):\n",
    "        \"\"\"\n",
    "        保存数据的方法。\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement this method.\")\n",
    "    \n",
    "class AdvancedDataSaver(DataSaveStrategy):\n",
    "    \"\"\"\n",
    "    高级的数据保存策\n",
    "    \"\"\"\n",
    "    def save_data(self, data, filename, file_description):\n",
    "        # 实现高级的数据保存逻辑\n",
    "        with h5py.File(filename, 'w') as h5f:\n",
    "            h5f.attrs['file_description'] = file_description\n",
    "            for key in data.columns:\n",
    "                dataset = h5f.create_dataset(key, data=data[key].values)\n",
    "                if key in COLUMN_DESCRIPTIONS:\n",
    "                    dataset.attrs['unit'] = COLUMN_DESCRIPTIONS[key]['unit']\n",
    "                    dataset.attrs['description'] = COLUMN_DESCRIPTIONS[key]['description']\n",
    "                    \n",
    "class DefaultDataSaver(DataSaveStrategy):\n",
    "    \"\"\"\n",
    "    默认的数据保存策略，使用data_save.py中的save_data_to_h5函数保存数据。\n",
    "    \"\"\"\n",
    "    def save_data(self, data, filename, file_description):\n",
    "        with h5py.File(filename, 'w') as h5f:\n",
    "            h5f.attrs['file_description'] = file_description\n",
    "            for key in data.columns:\n",
    "                dataset = h5f.create_dataset(key, data=data[key].values)\n",
    "                \n",
    "def save_data_to_h5_using_strategy(data, filename, file_description, strategy=DefaultDataSaver()):\n",
    "    strategy.save_data(data, filename, file_description)\n",
    "    \n",
    "# # 1. 默认数据保存策略\n",
    "# # 导入必要的库\n",
    "# import pandas as pd\n",
    "# import h5py\n",
    "\n",
    "# # 使用默认数据保存策略保存数据\n",
    "# filename = \"./well_log_daqing.h5\"\n",
    "# file_description = \"这是一个示例文件。\"\n",
    "# data_saver = DefaultDataSaver()\n",
    "# save_data_to_h5_using_strategy(df, filename, file_description, strategy=data_saver)\n",
    "# print(\"数据已保存为well_log_daqing.h5。\")\n",
    "\n",
    "# # 2. 高级数据保存策略\n",
    "# # 导入必要的库\n",
    "# import pandas as pd\n",
    "# import h5py\n",
    "\n",
    "# # 使用高级数据加载策略加载数据\n",
    "# filename = \"./well_log_daqing.h5\"\n",
    "# file_description = \"这是一个示例文件。\"\n",
    "# data_saver = AdvancedDataSaver()\n",
    "# save_data_to_h5_using_strategy(df, filename, file_description, strategy=data_saver)\n",
    "# print(\"数据已保存为well_log_daqing.h5。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码优化策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据优化，策略模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使得两个数据加载函数适用于不同的场景，采用一些设计模式和技巧重构函数。常见的设计模式和技巧，如工厂模式，策略模式，参数化工厂模式，以及如何使用装饰器来扩展函数的功能\n",
    "\n",
    "1. 工厂模式：一种创建对象的模式，提供了一种创建对象的方法，而不直接使用构造函数，这样可以为创建对象提供更多的灵活性。在这种情况下，可以创建一个工厂函数，根据输入参数选择不同的数据加载函数。\n",
    "2. 策略模式：策略模式定义了一系列算法，并将每一个算法封装起来，使它们可以相互替换。策略模式使得算法可以独立于使用它的客户端。\n",
    "3. 参数化工厂模式：参数化工厂模式是工厂模式的一种变体，允许客户端代码通过参数来指定所需的产品类型。\n",
    "4. 装饰器扩展功能：装饰器是一种强大的技术，可以用来修改或增强函数的行为，而无需修改函数本身。例如，可以创建一个装饰器来添加日志记录功能。\n",
    "\n",
    "通过设计模式和技巧，可以灵活地重构数据加载函数，使它们能够适应不同的场景和需求。选择哪种模式和技巧取决于具体需求和项目的复杂性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "场景：两个数据加载函数的主要区别在于它们如何处理数据集的加载和DataFrame的构建。一个函数直接从.h5文件中读取数据并返回。另一个是返回数据和文件描述信息。差异表明：数据加载函数可能需要处理不同的数据格式或需要提供不同级别的信息。\n",
    "\n",
    "采用策略模式：允许在运行时选择不同的数据加载策略，这对于处理不同数据格式或提供不同级别的信息非常有用。此外，策略模式使得代码更加模块化和可扩展，可以轻松添加数据加载策略而不需要修改现有代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "策略模式设计：\n",
    "\n",
    "1. 建立抽象基类，定义了所以数据加载策略必须实现的接口。\n",
    "2. 创建具体的数据加载策略类，分别实现不同的数据加载逻辑。\n",
    "3. 创建一个上下文类或者函数，用于选择和执行不同的数据加载策略。\n",
    "\n",
    "策略模式使用代码：\n",
    "\n",
    "1. 编写执行实例\n",
    "2. 使用上下文类或者函数选择和执行不同的数据加载策略。\n",
    "3. 测试不同的数据加载策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存数据优化，策略模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "策略模式设计数据保存的类，允许根据需要选择不同的数据保存策略来保存数据的类。\n",
    "设计将根据选择不同的数据策略，例如：保存为.h5文件，保存为.csv文件，保存为数据库等。\n",
    "\n",
    "策略模式设计：\n",
    "1. 首先定义一个抽象基类，为每种保存策略创建具体的实现类。\n",
    "2. 定义数据保存策略接口\n",
    "3. 实现具体的数据保存策略\n",
    "   1. 保存为.h5文件\n",
    "   2. 保存为.csv文件\n",
    "4. 使用数据保存策略\n",
    "5. 执行实例\n",
    "\n",
    "这种设计使得可以根据需要选择不同的数据保存策略，同时保持代码的清洗和模块化。通过传递不同的策略对象，可以轻松地改变数据保存的方式，而不需要修改sava_data_using_strategy函数的实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过继承和重写某些方法来实现更灵活的数据保存策略。将创建一个基础的数据保存类，为不同的报错策略创建子类。\n",
    "\n",
    "- 基础数据保存类：(注意，该基类的另外一种设计思路)\n",
    "- 具体的保存策略\n",
    "  - 保存每列数据为单独的数据集\n",
    "  - 保存整个DataFrame为单个数据集\n",
    "\n",
    "```python \n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "class BaseH5DataSaver:\n",
    "    def __init__(self, filename, file_description=None):\n",
    "        self.filename = filename\n",
    "        self.file_description = file_description\n",
    "\n",
    "    def save_data(self, data):\n",
    "        with h5py.File(self.filename, 'w') as h5f:\n",
    "            if self.file_description:\n",
    "                h5f.attrs['file_description'] = self.file_description\n",
    "            self._save_data_to_h5(data, h5f)\n",
    "\n",
    "    def _save_data_to_h5(self, data, h5f):\n",
    "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
